{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1- Logistic regresssion \n",
    "**Logistic regression** is a foundational statistical model used primarily for binary classification tasks, where it predicts the probability of an event occurring based on input variables. Despite its name, it's a linear model that fits data to a logistic (sigmoid) function, transforming the output into a probability score between 0 and 1. This makes it straightforward to interpret, as the predicted probability directly indicates the likelihood of an instance belonging to a specific class. Logistic regression is computationally efficient, making it suitable for large datasets, and it doesn't assume a particular distribution of input variables like Gaussian assumptions in other classifiers. It's commonly applied in scenarios such as predicting customer churn, identifying spam emails, or detecting fraudulent transactions. While logistic regression's linear decision boundary can be limiting in capturing complex relationships, its simplicity, interpretability, and robust performance as a baseline model make it indispensable in both statistical analysis and machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing\n",
    "Data preprocessing transforms raw data into a clean and usable format by handling missing values, outliers, and ensuring consistent data scales through normalization or standardization. It also includes feature extraction and selection to enhance dataset quality. This step is essential for efficient and accurate data analysis or machine learning model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessery Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the IMDb movie reviews dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#removal of stopwords \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#tokanize the text \n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['review'] = df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lemmitization \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['review'] = df['review'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(df['review'])\n",
    "y_train = df['sentiment']\n",
    "\n",
    "X_test = vectorizer.transform(df['review'])\n",
    "y_test = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Building\n",
    "Model building with logistic regression for binary classification involves steps as -The data is split into training and testing sets. A logistic regression model is trained on the training set, and its performance is evaluated on the test set using metrics like accuracy, precision, recall. Hyperparameter tuning can be performed to optimize the model. This process helps create a robust predictive model that can effectively classify binary outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_val)\n",
    "print(\"Logistic Regression Accuracy:\", log_reg.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8885\n",
      "Precision: 0.8790571870170015\n",
      "Recall: 0.9029569358999802\n",
      "F1-score: 0.8908467939304944\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_val and y_pred are numpy arrays\n",
    "y_val_numeric = np.where(y_val == 'positive', 1, 0)\n",
    "y_pred_numeric = np.where(y_pred == 'positive', 1, 0)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", log_reg.score(X_val, y_val))\n",
    "print(\"Precision:\", precision_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"Recall:\", recall_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"F1-score:\", f1_score(y_val_numeric, y_pred_numeric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      "[[22412  2588]\n",
      " [ 2058 22942]]\n",
      "\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91     25000\n",
      "    positive       0.90      0.92      0.91     25000\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.91      0.91      0.91     50000\n",
      "weighted avg       0.91      0.91      0.91     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_numeric = log_reg.predict(X_test) \n",
    "\n",
    "# Compute the confusion matrix and classification report\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(y_test, y_pred_numeric))\n",
    "print(\"\\nclassification_report\")\n",
    "print(classification_report(y_test, y_pred_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Output Analysis of Logistic Regression Model\n",
    "\n",
    "The logistic regression model achieved an overall accuracy of 0.91468, or approximately 91.47%, on the test set. This indicates that the model correctly classified 91.47% of the instances in the test data.\n",
    "\n",
    "The classification report provides more detailed performance metrics:\n",
    "\n",
    "### Negative Class Performance\n",
    "- **Precision**: 0.92\n",
    "- **Recall**: 0.90\n",
    "- **F1-score**: 0.91\n",
    "- **Support**: 25,000\n",
    "\n",
    "For the negative class, the model has a high precision of 92%, meaning that 92% of the instances predicted as negative are actually negative. The recall is also strong at 90%, indicating that the model correctly identifies 90% of the actual negative instances. The F1-score, which is the harmonic mean of precision and recall, is 0.91, reflecting the model's solid performance for the negative class.\n",
    "\n",
    "### Positive Class Performance\n",
    "- **Precision**: 0.90\n",
    "- **Recall**: 0.92\n",
    "- **F1-score**: 0.91\n",
    "- **Support**: 25,000\n",
    "\n",
    "For the positive class, the model's precision is 90%, indicating that 90% of the instances predicted as positive are indeed positive. The recall is slightly higher at 92%, meaning the model successfully identifies 92% of the actual positive instances. The F1-score for the positive class is also 0.91, demonstrating the model's balanced performance in identifying positive instances.\n",
    "\n",
    "### Overall Performance\n",
    "- **Accuracy**: 0.91\n",
    "- **Macro Average Precision**: 0.91\n",
    "- **Macro Average Recall**: 0.91\n",
    "- **Macro Average F1-score**: 0.91\n",
    "- **Weighted Average Precision**: 0.91\n",
    "- **Weighted Average Recall**: 0.91\n",
    "- **Weighted Average F1-score**: 0.91\n",
    "\n",
    "The overall accuracy of 91% confirms that the model performs well in classifying instances correctly. The macro average metrics provide the unweighted average of the metrics across both classes, showing that the model performs consistently well across the board. The weighted average metrics, which account for the equal distribution of classes (25,000 instances of both negative and positive classes), also indicate strong and balanced performance.\n",
    "\n",
    "### Summary\n",
    "In summary, the logistic regression model demonstrates strong and balanced performance with an overall accuracy of 91.47%. It performs well for both the negative and positive classes, with high precision, recall, and F1-scores across the board. The classification report highlights the model's ability to accurately distinguish between the two classes, making it a reliable model for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Logistic Regression model and TF-IDF vectorizer\n",
    "joblib.dump(log_reg, 'log_reg.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
