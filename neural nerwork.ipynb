{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the IMDb movie reviews dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing\n",
    "Data preprocessing transforms raw data into a clean and usable format by handling missing values, outliers, and ensuring consistent data scales through normalization or standardization. It also includes feature extraction and selection to enhance dataset quality. This step is essential for efficient and accurate data analysis or machine learning model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#removal of stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#tokanize the text\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['review'] = df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lemmitization \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['review'] = df['review'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(df['review'])\n",
    "y_train = df['sentiment']\n",
    "\n",
    "X_test = vectorizer.transform(df['review'])\n",
    "y_test = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MLPClassifier\n",
    "The MLPClassifier from sklearn.neural_network is a powerful and flexible tool for supervised machine learning tasks, specifically classification. It implements a feedforward neural network, often referred to as a multi-layer perceptron (MLP), which can capture complex patterns in data by learning from a set of labeled training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.8659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(64,), max_iter=1000)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nn.predict(X_val)\n",
    "print(\"Neural Network Accuracy:\", nn.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.5008930343322088\n",
      "F1-score: 0.5020387866732968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_numeric = y_pred_numeric[:len(y_val_numeric)]\n",
    "\n",
    "#  precision, recall, and F1-scoreprint(\"Precision:\", precision_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"Recall:\", recall_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"F1-score:\", f1_score(y_val_numeric, y_pred_numeric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5031897926634769\n",
      "Recall: 0.5008930343322088\n",
      "F1-score: 0.5020387866732968\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\", precision_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"Recall:\", recall_score(y_val_numeric, y_pred_numeric))\n",
    "print(\"F1-score:\", f1_score(y_val_numeric, y_pred_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      "[[24336   664]\n",
      " [  630 24370]]\n",
      "\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97     25000\n",
      "    positive       0.97      0.97      0.97     25000\n",
      "\n",
      "    accuracy                           0.97     50000\n",
      "   macro avg       0.97      0.97      0.97     50000\n",
      "weighted avg       0.97      0.97      0.97     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_numeric = nn.predict(X_test) \n",
    "\n",
    "#  the confusion matrix and classification report\n",
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(y_test, y_pred_numeric))\n",
    "print(\"\\nclassification_report\")\n",
    "print(classification_report(y_test, y_pred_numeric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Output Analysis of MLPClassifier (Simple Neural Network Model)\n",
    "\n",
    "The MLPClassifier model achieved an overall accuracy of 0.97344, or approximately 97.34%, on the test set. This indicates that the model correctly classified 97.34% of the instances in the test data.\n",
    "\n",
    "The classification report provides more detailed performance metrics:\n",
    "\n",
    "### Negative Class Performance\n",
    "- **Precision**: 0.97\n",
    "- **Recall**: 0.97\n",
    "- **F1-score**: 0.97\n",
    "- **Support**: 25,000\n",
    "\n",
    "For the negative class, the model has a precision of 97%, meaning that 97% of the instances predicted as negative are actually negative. The recall is also 97%, showing that the model correctly identifies 97% of the actual negative instances. The F1-score, which combines precision and recall, is 0.97, indicating the model's excellent performance in recognizing negative instances.\n",
    "\n",
    "### Positive Class Performance\n",
    "- **Precision**: 0.97\n",
    "- **Recall**: 0.97\n",
    "- **F1-score**: 0.97\n",
    "- **Support**: 25,000\n",
    "\n",
    "For the positive class, the model's performance is equally strong. The precision is 97%, meaning that 97% of the instances predicted as positive are indeed positive. The recall is also 97%, indicating that the model successfully identifies 97% of the actual positive instances. The F1-score for the positive class is 0.97, showing that the model is well-balanced and performs highly in identifying positive instances.\n",
    "\n",
    "### Overall Performance\n",
    "- **Accuracy**: 0.97\n",
    "- **Macro Average Precision**: 0.97\n",
    "- **Macro Average Recall**: 0.97\n",
    "- **Macro Average F1-score**: 0.97\n",
    "- **Weighted Average Precision**: 0.97\n",
    "- **Weighted Average Recall**: 0.97\n",
    "- **Weighted Average F1-score**: 0.97\n",
    "\n",
    "The overall accuracy of 97% demonstrates that the MLPClassifier model is highly effective in classifying instances correctly. The macro average metrics show an unweighted average across both classes, and the weighted average metrics take into account the equal distribution of classes (25,000 instances of both negative and positive classes). Both sets of metrics indicate that the model performs consistently well across all classes.\n",
    "\n",
    "### Summary\n",
    "In summary, the MLPClassifier model demonstrates outstanding performance with an overall accuracy of 97.34%. It performs exceptionally well for both the negative and positive classes, with high precision, recall, and F1-scores across the board. The classification report highlights the model's ability to accurately distinguish between the two classes, making it a highly reliable model for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(nn, 'nn.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
